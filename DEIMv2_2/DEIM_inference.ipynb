{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9bbd0c-dc87-466e-bbf3-54e1c6bd931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from engine.core import YAMLConfig\n",
    "from engine.misc import dist_utils\n",
    "from engine.data.transforms import Compose, Normalize, Resize, ConvertPILImage\n",
    "from engine.solver import TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee25a366-7fda-4b28-adb1-a8cd00c90c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfine_solver(config_path, checkpoint_path, device=\"cuda\"):\n",
    "\n",
    "    update_dict = {\n",
    "        \"resume\": None,\n",
    "        \"device\": device,\n",
    "        \"seed\": 42,\n",
    "        \"tuning\": checkpoint_path,\n",
    "        \"use_amp\": False,\n",
    "        \"use_ema\": True,\n",
    "    }\n",
    "\n",
    "    cfg = YAMLConfig(config_path, **update_dict)\n",
    "\n",
    "    if \"HGNetv2\" in cfg.yaml_cfg:\n",
    "        cfg.yaml_cfg[\"HGNetv2\"][\"pretrained\"] = False\n",
    "\n",
    "    # Solver ÏÉùÏÑ± (model, postprocessor, criterion Îì±ÏùÄ ÏïÑÏßÅ None)\n",
    "    SolverClass = TASKS[cfg.yaml_cfg[\"task\"]]\n",
    "    solver = SolverClass(cfg)\n",
    "\n",
    "    solver._setup()\n",
    "\n",
    "    # checkpoint load Î∞©ÏãùÎèÑ train.pyÏôÄ ÎèôÏùº\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    state = ckpt[\"model\"] if \"model\" in ckpt else ckpt[\"ema\"][\"module\"]\n",
    "    solver.model.load_state_dict(state, strict=False)\n",
    "\n",
    "    solver.model.to(device)\n",
    "    solver.model.eval()\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55036ec1-e513-415d-8573-17da7d4ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfine_test_inference(\n",
    "    config,\n",
    "    checkpoint,\n",
    "    image_dir,\n",
    "    output_csv=\"output.csv\",\n",
    "    threshold=0.01,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    print(\"üîÑ Loading model for Single Inference (Normalized)...\")\n",
    "    solver = load_dfine_solver(config, checkpoint, device)\n",
    "\n",
    "    model = solver.model\n",
    "    postprocessor = solver.postprocessor\n",
    "    model.eval()\n",
    "\n",
    "    # Ï†ïÍ∑úÌôî(Normalize) Ï∂îÍ∞Ä\n",
    "    transform = Compose([\n",
    "        Resize(size=[1024, 1024]),\n",
    "        ConvertPILImage(dtype=\"float32\", scale=True), # 0~255 -> 0.0~1.0 Î≥ÄÌôò\n",
    "        # Î™®Îç∏ ÌïôÏäµ Ïãú ÏÇ¨Ïö©Îêú ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞®Î°ú Ï†ïÍ∑úÌôî \n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image_paths = sorted(list(Path(image_dir).glob(\"*.jpg\"))) + \\\n",
    "                  sorted(list(Path(image_dir).glob(\"*.png\")))\n",
    "\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "\n",
    "    print(f\"Starting Inference on {len(image_paths)} images...\")\n",
    "\n",
    "    for img_path in tqdm(image_paths):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        w0, h0 = img.size\n",
    "\n",
    "        # Ï†ÑÏ≤òÎ¶¨ (Resize -> Scale -> Normalize)\n",
    "        img_tensor = transform(img)\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # model inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "\n",
    "        # Post-process (Ï¢åÌëú Î≥µÏõê)\n",
    "        pred = postprocessor(\n",
    "            outputs,\n",
    "            orig_target_sizes=torch.tensor([[h0, w0]], device=device)\n",
    "        )[0]\n",
    "\n",
    "        boxes = pred[\"boxes\"].cpu().numpy()\n",
    "        scores = pred[\"scores\"].cpu().numpy()\n",
    "        labels = pred[\"labels\"].cpu().numpy()\n",
    "\n",
    "        pred_str = \"\"\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            if score < threshold:\n",
    "                continue\n",
    "            \n",
    "            label = int(label)\n",
    "            x1, y1, x2, y2 = box\n",
    "            # ÏÜåÏàòÏ†ê 4ÏûêÎ¶¨ÍπåÏßÄ Ï†ÄÏû• (Ï†ïÎ∞ÄÎèÑ Ïú†ÏßÄ)\n",
    "            pred_str += f\"{label} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \"\n",
    "\n",
    "        predictions.append(pred_str.strip())\n",
    "        filenames.append(f\"test/{img_path.name}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"PredictionString\": predictions,\n",
    "        \"image_id\": filenames,\n",
    "    })\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"üìÑ CSV saved ‚Üí {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50d65a5-efa6-47d4-bb4a-59a440e7f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading model for Single Inference (Normalized)...\n",
      "Training DINOv3 from scratch...\n",
      "Using Lite Spatial Prior Module with inplanes=64\n",
      "     --- Use Gateway@True ---\n",
      "     --- Use Share Bbox Head@False ---\n",
      "     --- Use Share Score Head@False ---\n",
      "     --- Wide Layer@1 ---\n",
      "Tuning checkpoint from ./outputs/deimv2_dinov3_x_coco/checkpoint0019.pth\n",
      "Load model.state_dict, {'missed': [], 'unmatched': []}\n",
      "Using the new matching cost with iou_order_alpha = 4.0 at epoch 45\n",
      "üöÄ Starting Inference on 4871 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4871/4871 [15:17<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ CSV saved ‚Üí deimv2_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 0.9821 604.12 518.01 956.29 1024.20 7 0.9752...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 0.9191 344.26 249.83 752.80 694.60 5 0.8249 ...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 0.9558 775.86 407.55 1024.15 1024.50 1 0.930...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 0.9813 146.37 262.66 911.80 823.56 9 0.6196 ...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 0.9446 198.11 252.49 872.56 779.42 0 0.7777 ...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  7 0.9821 604.12 518.01 956.29 1024.20 7 0.9752...  test/0000.jpg\n",
       "1  4 0.9191 344.26 249.83 752.80 694.60 5 0.8249 ...  test/0001.jpg\n",
       "2  1 0.9558 775.86 407.55 1024.15 1024.50 1 0.930...  test/0002.jpg\n",
       "3  9 0.9813 146.37 262.66 911.80 823.56 9 0.6196 ...  test/0003.jpg\n",
       "4  1 0.9446 198.11 252.49 872.56 779.42 0 0.7777 ...  test/0004.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfine_test_inference( ## XÎ≤ÑÏ†Ñ\n",
    "    config=\"./configs/deimv2/deimv2_dinov3_x_coco.yml\",\n",
    "    checkpoint=\"./outputs/deimv2_dinov3_x_coco/checkpoint0019.pth\",\n",
    "    image_dir=\"../dataset/test\",\n",
    "    output_csv=\"deimv2_submission.csv\",\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0c12b-30ec-414e-a077-f361bba52ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyth\non (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
