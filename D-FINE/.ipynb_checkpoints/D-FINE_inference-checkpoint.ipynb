{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115c0359-1c67-4720-998f-e1807e7c1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from src.core import YAMLConfig\n",
    "from src.misc import dist_utils\n",
    "from src.data.transforms import Compose, Resize, ConvertPILImage\n",
    "from src.solver import TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf208c5e-e061-4374-bf89-44dbd4ba925e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (1617811176.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    =\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "def load_dfine_solver(config_path, checkpoint_path, device=\"cuda\"):\n",
    "\n",
    "    update_dict = {\n",
    "        \"resume\": None,\n",
    "        \"device\": device,\n",
    "        \"seed\": 42,\n",
    "        \"tuning\": checkpoint_path,\n",
    "        \"use_amp\": False,\n",
    "        \"use_ema\": True,\n",
    "    }\n",
    "\n",
    "    cfg = YAMLConfig(config_path, **update_dict)\n",
    "\n",
    "    if \"HGNetv2\" in cfg.yaml_cfg:\n",
    "        cfg.yaml_cfg[\"HGNetv2\"][\"pretrained\"] = False\n",
    "\n",
    "    # Solver ÏÉùÏÑ± (model, postprocessor, criterion Îì±ÏùÄ ÏïÑÏßÅ None)\n",
    "    SolverClass = TASKS[cfg.yaml_cfg[\"task\"]]\n",
    "    solver = SolverClass(cfg)\n",
    "\n",
    "    solver._setup()\n",
    "\n",
    "    # checkpoint load Î∞©ÏãùÎèÑ train.pyÏôÄ ÎèôÏùº\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    state = ckpt[\"model\"] if \"model\" in ckpt else ckpt[\"ema\"][\"module\"]\n",
    "    solver.model.load_state_dict(state, strict=False)\n",
    "\n",
    "    solver.model.to(device)\n",
    "    solver.model.eval()\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655ee99-c97c-44f5-b967-368453417333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfine_test_inference(\n",
    "    config,\n",
    "    checkpoint,\n",
    "    image_dir,\n",
    "    output_csv=\"output.csv\",\n",
    "    threshold=0.05,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "\n",
    "    solver = load_dfine_solver(config, checkpoint, device)\n",
    "\n",
    "    model = solver.model\n",
    "    postprocessor = solver.postprocessor\n",
    "\n",
    "    transform = Compose([\n",
    "        Resize(size=[1024,1024]),\n",
    "        ConvertPILImage(dtype=\"float32\", scale=True),\n",
    "    ])\n",
    "\n",
    "    image_paths = sorted(list(Path(image_dir).glob(\"*.jpg\"))) + \\\n",
    "                  sorted(list(Path(image_dir).glob(\"*.png\")))\n",
    "\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "\n",
    "    for img_path in tqdm(image_paths):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        w0, h0 = img.size\n",
    "\n",
    "        img_tensor = transform(img)\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # model inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "\n",
    "        pred = postprocessor(\n",
    "            outputs,\n",
    "            orig_target_sizes=torch.tensor([[h0, w0]], device=device)\n",
    "        )[0]\n",
    "\n",
    "        boxes = pred[\"boxes\"].cpu().numpy()\n",
    "        scores = pred[\"scores\"].cpu().numpy()\n",
    "        labels = pred[\"labels\"].cpu().numpy()\n",
    "\n",
    "        pred_str = \"\"\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            if score < threshold:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = box\n",
    "            pred_str += f\"{label} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \"\n",
    "\n",
    "        predictions.append(pred_str.strip())\n",
    "        filenames.append(f\"test/{img_path.name}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"PredictionString\": predictions,\n",
    "        \"image_id\": filenames,\n",
    "    })\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"üìÑ CSV saved ‚Üí {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cda67-a18a-4fbe-af13-fb59989a1b6c",
   "metadata": {},
   "source": [
    "# TTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc6ca370-789a-4120-9b98-556e79873668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from torchvision.ops import nms\n",
    "# from ensemble_boxes import weighted_boxes_fusion\n",
    "\n",
    "\n",
    "# def tta_inference(model, img_tensor, orig_size, postprocessor, device=\"cuda\"):\n",
    "#     \"\"\"\n",
    "#     img_tensor: (1, 3, H, W)\n",
    "#     orig_size: (h0, w0)\n",
    "#     \"\"\"\n",
    "\n",
    "#     h0, w0 = orig_size\n",
    "\n",
    "#     # 1) ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ inference\n",
    "#     with torch.no_grad():\n",
    "#         out_original = model(img_tensor)\n",
    "\n",
    "#     pred_original = postprocessor(\n",
    "#         out_original,\n",
    "#         orig_target_sizes=torch.tensor([[h0, w0]], device=device)\n",
    "#     )[0]\n",
    "\n",
    "#     # 2) horizontal flip TTA\n",
    "#     img_flipped = torch.flip(img_tensor, dims=[3])  # width Î∞©Ìñ• flip\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         out_flip = model(img_flipped)\n",
    "\n",
    "#     pred_flip = postprocessor(\n",
    "#         out_flip,\n",
    "#         orig_target_sizes=torch.tensor([[h0, w0]], device=device)\n",
    "#     )[0]\n",
    "\n",
    "#     # 3) flipÎêú Í≤∞Í≥ºÎ•º Îã§Ïãú ÏõêÎûò Ï¢åÌëúÍ≥ÑÎ°ú Î≥ÄÌôò\n",
    "#     boxes = pred_flip[\"boxes\"].cpu().numpy()\n",
    "#     boxes[:, [0, 2]] = w0 - boxes[:, [2, 0]]  # x1,x2 swap\n",
    "\n",
    "#     pred_flip[\"boxes\"] = torch.tensor(boxes)\n",
    "#     pred_flip[\"scores\"] = pred_flip[\"scores\"]\n",
    "#     pred_flip[\"labels\"] = pred_flip[\"labels\"]\n",
    "\n",
    "#     # 4) original + flip ensemble (concat Ï†ïÎèÑÎ©¥ Ï∂©Î∂Ñ)\n",
    "#     final_boxes = torch.cat([\n",
    "#         pred_original[\"boxes\"].cpu(),\n",
    "#         pred_flip[\"boxes\"].cpu()\n",
    "#     ])\n",
    "\n",
    "#     final_scores = torch.cat([\n",
    "#         pred_original[\"scores\"].cpu(),\n",
    "#         pred_flip[\"scores\"].cpu()\n",
    "#     ])\n",
    "\n",
    "#     final_labels = torch.cat([\n",
    "#         pred_original[\"labels\"].cpu(),\n",
    "#         pred_flip[\"labels\"].cpu()\n",
    "#     ])\n",
    "\n",
    "#     return final_boxes, final_scores, final_labels\n",
    "\n",
    "\n",
    "# def tta_nms(boxes, scores, labels, iou_thr=0.6):\n",
    "#     keep = nms(boxes, scores, iou_thr)\n",
    "#     return boxes[keep], scores[keep], labels[keep]\n",
    "\n",
    "# def tta_wbf(boxes, scores, labels, image_size, iou_thr=0.6, skip_box_thr=0.0):\n",
    "#     \"\"\"\n",
    "#     boxes: (N, 4) torch tensor, x1,y1,x2,y2 (pixel Îã®ÏúÑ)\n",
    "#     scores: (N,) torch tensor\n",
    "#     labels: (N,) torch tensor\n",
    "#     image_size: (w0, h0) ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞\n",
    "#     \"\"\"\n",
    "#     w0, h0 = image_size\n",
    "\n",
    "#     # to numpy\n",
    "#     boxes_np = boxes.detach().cpu().numpy()\n",
    "#     scores_np = scores.detach().cpu().numpy()\n",
    "#     labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "#     # 0~1 Î°ú Ï†ïÍ∑úÌôî (ensemble-boxes Í∑úÍ≤©)\n",
    "#     boxes_norm = boxes_np.copy()\n",
    "#     boxes_norm[:, [0, 2]] /= float(w0)\n",
    "#     boxes_norm[:, [1, 3]] /= float(h0)\n",
    "\n",
    "#     # WBFÎäî Î™®Îç∏Î≥Ñ Î¶¨Ïä§Ìä∏Î•º Î∞õÏúºÎØÄÎ°ú, TTA Ï†ÑÏ≤¥Î•º ÌïòÎÇòÏùò Î™®Îç∏Î°ú Î≥∏Îã§.\n",
    "#     boxes_list = [boxes_norm]\n",
    "#     scores_list = [scores_np]\n",
    "#     labels_list = [labels_np]\n",
    "\n",
    "#     boxes_wbf, scores_wbf, labels_wbf = weighted_boxes_fusion(\n",
    "#         boxes_list,\n",
    "#         scores_list,\n",
    "#         labels_list,\n",
    "#         weights=None,\n",
    "#         iou_thr=iou_thr,\n",
    "#         skip_box_thr=skip_box_thr\n",
    "#     )\n",
    "\n",
    "#     # Îã§Ïãú ÌîΩÏÖÄ Ï¢åÌëúÎ°ú ÎêòÎèåÎ¶¨Í∏∞\n",
    "#     boxes_wbf[:, [0, 2]] *= float(w0)\n",
    "#     boxes_wbf[:, [1, 3]] *= float(h0)\n",
    "\n",
    "#     # Îã§Ïãú torch tensor Î°ú Î≥ÄÌôò\n",
    "#     device = boxes.device\n",
    "#     boxes_out = torch.tensor(boxes_wbf, device=device, dtype=boxes.dtype)\n",
    "#     scores_out = torch.tensor(scores_wbf, device=device, dtype=scores.dtype)\n",
    "#     labels_out = torch.tensor(labels_wbf, device=device, dtype=labels.dtype)\n",
    "\n",
    "#     return boxes_out, scores_out, labels_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f44a31c3-62ac-4307-ab5b-68d457830a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TTAÏ†ÅÏö©Î≤ÑÏ†Ñ\n",
    "# from pathlib import Path\n",
    "\n",
    "# def dfine_test_inference_TTA(\n",
    "#     config,\n",
    "#     checkpoint,\n",
    "#     image_dir,\n",
    "#     output_csv=\"output.csv\",\n",
    "#     threshold=0.05,\n",
    "#     device=\"cuda\"\n",
    "# ):\n",
    "\n",
    "#     solver = load_dfine_solver(config, checkpoint, device)\n",
    "\n",
    "#     model = solver.model\n",
    "#     postprocessor = solver.postprocessor\n",
    "\n",
    "#     transform = Compose([\n",
    "#         Resize(size=[1024,1024]),\n",
    "#         ConvertPILImage(dtype=\"float32\", scale=True),\n",
    "#     ])\n",
    "\n",
    "#     image_paths = sorted(list(Path(image_dir).glob(\"*.jpg\"))) + \\\n",
    "#                   sorted(list(Path(image_dir).glob(\"*.png\")))\n",
    "\n",
    "#     predictions = []\n",
    "#     filenames = []\n",
    "\n",
    "#     for img_path in tqdm(image_paths):\n",
    "#         img = Image.open(img_path).convert(\"RGB\")\n",
    "#         w0, h0 = img.size\n",
    "\n",
    "#         img_tensor = transform(img)\n",
    "#         img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "#         # ‚òÖ TTA inference Ï†ÅÏö© Î∂ÄÎ∂Ñ ‚òÖ\n",
    "#         boxes, scores, labels = tta_inference(\n",
    "#             model=model,\n",
    "#             img_tensor=img_tensor,\n",
    "#             orig_size=(h0, w0),\n",
    "#             postprocessor=postprocessor,\n",
    "#             device=device\n",
    "#         )\n",
    "        \n",
    "#         # boxes, scores, labels = tta_nms(\n",
    "#         #     boxes, scores, labels, iou_thr=0.6\n",
    "#         # )\n",
    "#         boxes, scores, labels = tta_wbf(\n",
    "#             boxes, scores, labels,\n",
    "#             image_size=(w0, h0),\n",
    "#             iou_thr=0.6,\n",
    "#             skip_box_thr=threshold\n",
    "#         )\n",
    "        \n",
    "#         boxes = boxes.numpy()\n",
    "#         scores = scores.numpy()\n",
    "#         labels = labels.numpy()\n",
    "\n",
    "#         pred_str = \"\"\n",
    "#         for box, score, label in zip(boxes, scores, labels):\n",
    "#             if score < threshold:\n",
    "#                 continue\n",
    "#             x1, y1, x2, y2 = box\n",
    "#             pred_str += f\"{label} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \"\n",
    "\n",
    "#         predictions.append(pred_str.strip())\n",
    "#         filenames.append(f\"test/{img_path.name}\")\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         \"PredictionString\": predictions,\n",
    "#         \"image_id\": filenames,\n",
    "#     })\n",
    "\n",
    "#     df.to_csv(output_csv, index=False)\n",
    "#     print(f\"üìÑ CSV saved ‚Üí {output_csv}\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8795a843-f758-4c4b-9ebb-a934b4179ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfine_test_inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdfine_test_inference\u001b[49m( \u001b[38;5;66;03m#_TTA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs/dfine/custom/dfine_hgnetv2_l_custom.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output/dfine_hgnetv2_l_custom/last.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     image_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../dataset_for_RFDETR/test/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     output_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfine_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfine_test_inference' is not defined"
     ]
    }
   ],
   "source": [
    "df = dfine_test_inference( #_TTA\n",
    "    config=\"configs/dfine/custom/dfine_hgnetv2_l_custom.yml\",\n",
    "    checkpoint=\"./output/dfine_hgnetv2_l_custom/last.pth\",\n",
    "    image_dir=\"../../dataset_for_RFDETR/test/test\",\n",
    "    output_csv=\"dfine_submission.csv\",\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee9cc8-9e6f-40e4-9f95-5d67e717b7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa5b91-9644-4644-9d1c-3d75ea0fde6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybum",
   "language": "python",
   "name": "pybum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
